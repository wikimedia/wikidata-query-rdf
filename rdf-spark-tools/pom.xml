<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
    <modelVersion>4.0.0</modelVersion>
    <parent>
        <groupId>org.wikidata.query.rdf</groupId>
        <artifactId>query-service-parent</artifactId>
        <version>0.3.150</version>
    </parent>
    <artifactId>rdf-spark-tools</artifactId>
    <packaging>jar</packaging>
    <description>Tools to manipulate wikibase RDF dumps using spark.</description>
    <licenses>
        <license>
            <name>The Apache Software License, Version 2.0</name>
            <url>http://www.apache.org/licenses/LICENSE-2.0.txt</url>
            <distribution>repo</distribution>
        </license>
    </licenses>
    <!-- pom credits:
      inspired from https://github.com/martinprobson/Spark-Scala-Maven-Example
      and https://gerrit.wikimedia.org/g/analytics/refinery/source
      -->
    <properties>
        <hadoop.version>3.3.2</hadoop.version>
        <scala.compat.version>2.12</scala.compat.version>
        <scala.scalatest-maven-plugin.version>2.2.0</scala.scalatest-maven-plugin.version>
        <scala.scalatest.version>3.2.15</scala.scalatest.version>
        <scala.version>2.12.17</scala.version>
        <spark.version>3.3.1</spark.version>
    </properties>
    <!-- use dependencyManagement here to enforce versions of transitive dependencies -->
    <dependencyManagement>
        <!-- enforce compatibility with spark-core -->
        <dependencies>
            <dependency>
                <groupId>com.ibm.icu</groupId>
                <artifactId>icu4j</artifactId>
                <version>68.1</version>
            </dependency>
            <dependency>
                <groupId>com.thoughtworks.paranamer</groupId>
                <artifactId>paranamer</artifactId>
                <version>2.8</version>
            </dependency>
            <dependency>
                <groupId>org.apache.commons</groupId>
                <artifactId>commons-lang3</artifactId>
                <version>3.12.0</version>
            </dependency>
            <dependency>
                <groupId>org.codehaus.janino</groupId>
                <artifactId>janino</artifactId>
                <version>3.0.16</version>
            </dependency>
            <!-- Force the guava version used inside the WMF hadoop cluster -->
            <dependency>
                <groupId>com.google.guava</groupId>
                <artifactId>guava</artifactId>
                <version>11.0.2</version>
                <scope>provided</scope>
            </dependency>
            <dependency>
                <groupId>org.scalactic</groupId>
                <artifactId>scalactic_${scala.compat.version}</artifactId>
                <version>3.2.15</version>
                <scope>test</scope>
            </dependency>
        </dependencies>
    </dependencyManagement>
    <dependencies>
        <!-- Scala lang, spark core and spark sql are all
             scoped as provided as spark-submit will provide these -->
        <dependency>
            <groupId>com.github.scopt</groupId>
            <artifactId>scopt_${scala.compat.version}</artifactId>
        </dependency>
        <dependency>
            <groupId>com.holdenkarau</groupId>
            <artifactId>spark-testing-base_${scala.compat.version}</artifactId>
            <version>${spark.version}_1.3.0</version>
            <exclusions>
                <exclusion>
                    <groupId>javax.inject</groupId>
                    <artifactId>javax.inject</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>stax</groupId>
                    <artifactId>stax-api</artifactId>
                </exclusion>
                <exclusion>
                    <!-- comes with org.datanucleus:datanucleus-api-jdo -->
                    <groupId>javax.jdo</groupId>
                    <artifactId>jdo-api</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>com.ibm.icu</groupId>
            <artifactId>icu4j</artifactId>
        </dependency>
        <dependency>
            <groupId>io.dropwizard.metrics</groupId>
            <artifactId>metrics-core</artifactId>
        </dependency>
        <dependency>
            <groupId>org.apache.jena</groupId>
            <artifactId>jena-arq</artifactId>
            <exclusions>
                <!-- exclude jackson to use the one provided by spark -->
                <exclusion>
                    <groupId>com.fasterxml.jackson.core</groupId>
                    <artifactId>jackson-core</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>org.openrdf.sesame</groupId>
            <artifactId>sesame-rio-ntriples</artifactId>
        </dependency>
        <dependency>
            <groupId>org.slf4j</groupId>
            <artifactId>slf4j-api</artifactId>
        </dependency>
        <dependency>
            <groupId>org.wikidata.query.rdf</groupId>
            <artifactId>tools</artifactId>
            <version>${project.version}</version>
            <exclusions>
                <!-- exclude jackson to use the one provided by spark (keep jsr310 for datetime) -->
                <exclusion>
                    <groupId>com.fasterxml.jackson.core</groupId>
                    <artifactId>jackson-annotations</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>com.fasterxml.jackson.core</groupId>
                    <artifactId>jackson-core</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>com.fasterxml.jackson.core</groupId>
                    <artifactId>jackson-databind</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>org.apache.kafka</groupId>
                    <artifactId>kafka-clients</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>org.wikimedia</groupId>
            <artifactId>eventutilities-shaded</artifactId>
            <exclusions>
                <!-- exclude jackson to use the one provided by spark -->
                <exclusion>
                    <groupId>com.fasterxml.jackson.datatype</groupId>
                    <artifactId>jackson-datatype-jsr310</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>com.fasterxml.jackson.core</groupId>
                    <artifactId>jackson-annotations</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>com.fasterxml.jackson.core</groupId>
                    <artifactId>jackson-core</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>com.fasterxml.jackson.core</groupId>
                    <artifactId>jackson-databind</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>org.apache.kafka</groupId>
                    <artifactId>kafka-clients</artifactId>
                </exclusion>
                <exclusion>
                    <!-- via com.github.java-json-tools:json-schema-validator -->
                    <groupId>javax.activation</groupId>
                    <artifactId>activation</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>org.yaml</groupId>
                    <artifactId>snakeyaml</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-core_${scala.compat.version}</artifactId>
            <scope>provided</scope>
            <exclusions>
                <exclusion>
                    <groupId>org.objenesis</groupId>
                    <artifactId>objenesis</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>javax.activation</groupId>
                    <artifactId>activation</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>javax.annotation</groupId>
                    <artifactId>javax.annotation-api</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>javax.ws.rs</groupId>
                    <artifactId>javax.ws.rs-api</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>javax.xml.bind</groupId>
                    <artifactId>jaxb-api</artifactId>
                </exclusion>
                <!-- spark included version is breaking builds on newer JDKs than 8 -->
                <exclusion>
                    <groupId>org.apache.xbean</groupId>
                    <artifactId>xbean-asm6-shaded</artifactId>
                </exclusion>
                <exclusion>
                    <!-- comes with org.apache.hadoop:hadoop-client-runtime -->
                    <groupId>org.apache.hadoop.thirdparty</groupId>
                    <artifactId>hadoop-shaded-guava</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>log4j</groupId>
                    <artifactId>log4j</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-sql_${scala.compat.version}</artifactId>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.scala-lang</groupId>
            <artifactId>scala-compiler</artifactId>
            <version>${scala.version}</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.scala-lang</groupId>
            <artifactId>scala-library</artifactId>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.scalamock</groupId>
            <artifactId>scalamock_${scala.compat.version}</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.scalatest</groupId>
            <artifactId>scalatest_${scala.compat.version}</artifactId>
            <scope>test</scope>
        </dependency>
    </dependencies>
    <repositories>
        <repository>
            <id>artima</id>
            <url>https://repo.artima.com/releases/</url>
        </repository>
    </repositories>
    <build>
        <plugins>
            <plugin>
                <!-- see http://davidb.github.com/scala-maven-plugin -->
                <groupId>net.alchim31.maven</groupId>
                <artifactId>scala-maven-plugin</artifactId>
                <version>4.8.0</version>
                <configuration>
                    <scalaVersion>${scala.version}</scalaVersion>
                    <args combine.children="append">
                        <arg>-Ywarn-unused</arg>
                    </args>
                </configuration>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-assembly-plugin</artifactId>
                <executions>
                    <execution>
                        <id>jar-with-dependencies</id>
                        <goals>
                            <goal>single</goal>
                        </goals>
                        <phase>package</phase>
                        <configuration>
                            <descriptorRefs>
                                <descriptorRef>jar-with-dependencies-spi-compliant</descriptorRef>
                            </descriptorRefs>
                        </configuration>
                    </execution>
                    <execution>
                        <id>spark-client</id>
                        <goals>
                            <goal>single</goal>
                        </goals>
                        <phase>package</phase>
                        <configuration>
                            <descriptors>
                                <descriptor>src/assembly/spark-free.xml</descriptor>
                            </descriptors>
                        </configuration>
                    </execution>
                </executions>
            </plugin>
            <!-- disable surefire -->
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-surefire-plugin</artifactId>
                <configuration>
                    <useFile>false</useFile>
                    <disableXmlReport>true</disableXmlReport>
                    <includes>
                        <include>**/*Test.*</include>
                        <include>**/*Suite.*</include>
                    </includes>
                </configuration>
            </plugin>
            <plugin>
                <groupId>org.basepom.maven</groupId>
                <artifactId>duplicate-finder-maven-plugin</artifactId>
                <configuration>
                    <ignoredClassPatterns>
                        <ignoredClassPattern>org.apache.spark.unused.UnusedStubClass</ignoredClassPattern>
                        <ignoredClassPattern>dev.ludovic.netlib.InstanceBuilder</ignoredClassPattern>
                        <!-- unable to exclude either one: org.apache.hive:hive-common:2.3.9 (test), org.apache.hive:hive-storage-api:2.7.2 (provided) -->
                        <ignoredClassPattern>org.apache.hadoop.hive.common.ValidReadTxnList</ignoredClassPattern>
                        <ignoredClassPattern>org.apache.hadoop.hive.common.ValidTxnList</ignoredClassPattern>
                    </ignoredClassPatterns>
                    <ignoredResourcePatterns>
                        <ignoredResourcePattern>git.properties</ignoredResourcePattern>
                        <ignoredResourcePattern>codegen/config.fmpp$</ignoredResourcePattern>
                        <ignoredResourcePattern>log4j.properties$</ignoredResourcePattern>
                        <ignoredResourcePattern>parquet.thrift$</ignoredResourcePattern>
                        <ignoredResourcePattern>plugin.xml$</ignoredResourcePattern>
                        <ignoredResourcePattern>jetty-dir.css$</ignoredResourcePattern>
                        <ignoredResourcePattern>mozilla/public-suffix-list.txt$</ignoredResourcePattern>
                    </ignoredResourcePatterns>
                    <ignoredDependencies>
                        <!--
                            the following dependencies are problematic but non trivial to
                            clean, it will come in a second time...
                          -->
                        <dependency>
                            <groupId>commons-logging</groupId>
                            <artifactId>commons-logging</artifactId>
                        </dependency>
                        <dependency>
                            <groupId>commons-beanutils</groupId>
                            <artifactId>commons-beanutils-core</artifactId>
                        </dependency>
                        <dependency>
                            <groupId>commons-beanutils</groupId>
                            <artifactId>commons-beanutils</artifactId>
                        </dependency>
                        <dependency>
                            <groupId>org.glassfish.hk2.external</groupId>
                            <artifactId>aopalliance-repackaged</artifactId>
                        </dependency>
                        <dependency>
                            <groupId>org.glassfish.hk2.external</groupId>
                            <artifactId>javax.inject</artifactId>
                        </dependency>
                        <dependency>
                            <groupId>org.glassfish.jersey.core</groupId>
                            <artifactId>jersey-server</artifactId>
                        </dependency>
                        <dependency>
                            <groupId>xml-apis</groupId>
                            <artifactId>xml-apis</artifactId>
                        </dependency>
                        <dependency>
                            <groupId>javax.servlet</groupId>
                            <artifactId>servlet-api</artifactId>
                        </dependency>
                        <dependency>
                            <groupId>com.sun.jersey</groupId>
                            <artifactId>jersey-core</artifactId>
                        </dependency>
                        <dependency>
                            <!-- spark core has log4j12 but need logback because
                                 of common. Silence the checker for now time
                                 to figure out if spark complains at runtime
                                 -->
                            <groupId>org.slf4j</groupId>
                            <artifactId>slf4j-log4j12</artifactId>
                        </dependency>
                        <dependency>
                            <!-- dup of rootdoc.txt with org.scala-lang:scala-compiler:2.11.0 -->
                            <groupId>org.scala-lang</groupId>
                            <artifactId>scala-library</artifactId>
                        </dependency>
                        <dependency>
                            <!-- dup of some .package-info with org.apache.hadoop:hadoop-yarn-common:2.2.0 -->
                            <groupId>org.apache.hadoop</groupId>
                            <artifactId>hadoop-yarn-api</artifactId>
                        </dependency>
                    </ignoredDependencies>
                </configuration>
            </plugin>
            <plugin>
                <groupId>org.scalastyle</groupId>
                <artifactId>scalastyle-maven-plugin</artifactId>
            </plugin>
            <!-- enable scalatest -->
            <plugin>
                <groupId>org.scalatest</groupId>
                <artifactId>scalatest-maven-plugin</artifactId>
                <configuration>
                    <systemProperties>
                        <spark.sql.shuffle.partitions>2</spark.sql.shuffle.partitions>
                    </systemProperties>
                </configuration>
            </plugin>
        </plugins>
        <sourceDirectory>src/main/scala</sourceDirectory>
        <testSourceDirectory>src/test/scala</testSourceDirectory>
    </build>
</project>
